# gpu config
accelerator: gpu
num_nodes: 1
devices: 1

use_distill: false
recon_dir: /primus_biz_workspace/zhangboyang.zby/lscodec/recon_dir

lambda_kwargs:
  commit_loss_coeff: 10.0
  mel_loss_coeff: 45.0
  mrd_loss_coeff: 1.0
  waveform_loss_coeff: 0.1
  distill_loss_coeff: 10.0


# log config
log_dir: ./log/log1111
resume_from_last_ckpt: true
discriminator_start_step: 10
#resume: /root/code/lscodec/lscodec-checkpoint67.safetensors
resume: null
pretrained_pt_path: /root/code/lscodec/pretrained.pt
every_n_train_steps: 50
# inference
ckpt_path: null


# dataset config
dataset_config:
  train_kwargs:
    batch_size: 4
    cut_duration: 3.0  # 5.0 seconds
    num_workers: 1 # set 1 for debug
    prefetch: 24
    samples_per_epoch: 1000000
    speech_scp_path:
      - /primus_biz_workspace/zhangboyang.zby/data/emilia/train/data.list


max_steps: 1_200_000 


gradient_clip_val: 5.0
opt_gen:
  lr: 3.0e-4
opt_disc:
  lr: 3.0e-4
sch:
  warmup_steps: 0
perceptual_start_step: 500_000









